{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "local-ideal",
   "metadata": {},
   "source": [
    "# **Collaborative recommender module**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bottom-morgan",
   "metadata": {},
   "source": [
    "## **Introduction**\n",
    "\n",
    "Collaborative recommender module is constructed to make personalized recommendations that are highly rated by users having similar user profiles.\n",
    "\n",
    "Yelp dataset contains about 200K business, 2M users and 8M reviews, the user - restaurants interaction matrix would be a sparse matrix. Thus matrix factorization algorithms are used to construct the matrix and provide recommendations.\n",
    "\n",
    "## **Implementation Strategy**\n",
    "\n",
    "### 1 **Ranking**\n",
    "#### 1.1 **SVD (Singular Value Decomposition)**\n",
    "#### 1.1.1 **SVD without bias** \n",
    "The user - retaurants matrix is factorized into user latent features and restaurants latent features matrix using SVD algorithm.\n",
    "\n",
    "#### 1.1.2 **SVD with bias**\n",
    "To the original SVD matrices, user bias and restaurant bias matrix are introduced. \n",
    "\n",
    "`pred_rating = user latent features X restaurants latent features + user bias + restaurants bias + global_mean `\n",
    "\n",
    "#### 1.2 **NMF (Non negative matrix factorization)**\n",
    "#### 1.2.1 **NMF without bias**\n",
    "The user - retaurants matrix is factorized into non negative user latent features and non negative restaurants latent features matrix using NMF algorithm.\n",
    "\n",
    "#### 1.2.2 **NMF with bias**\n",
    "To the original NMF matrices, user bias and restaurant bias matrix are introduced.\n",
    "\n",
    "`scikit-suprise`, and `scikit-learn` packages are used fro prototyping the mentioned algorithms. Prototyping results indicates, amongst all four algorithms SVD with bias and NMF without bias provides acceptable ratings predictions. Being flexible, and best performing SVD with bias is used for module implementation. \n",
    "\n",
    "### 2 **Implementation**\n",
    "\n",
    "#### 2.1 **Optimization**\n",
    "Based on the prototyping results SVD with bias algorithm is optimized via gridsearch cross validation. \n",
    "\n",
    "#### 2.2 **Evaluation**\n",
    "**RMSE** <br>\n",
    "of the model are ----------- for testset with new users or restaurants, testset with no new users or restaurants, and testset with only users or restaurants with more than 5 ratings. \n",
    "\n",
    "**NDCG** <br>\n",
    "\n",
    "#### 2.3 **Module Development**\n",
    "1. All relevant restaurants are filtered for Collaborative Recommendations module\n",
    "2. Extracted latent matrix, bias matrix for user and item from trained, optimized SVD algorithm are fed to class\n",
    "3. For given user id, ratings are predicted for all filtered restaurants by multiplying user laten and item latent, adding biases for user, item as well as global mean ratings\n",
    "4. Predicted ratings are paired with correspoding restaurants and filtered the list by unrated restaurants by user\n",
    "5. Recommendations from this module are merged with content based recommender module's recommendations and after sorting the list by predicted ratings, final recommendations are displayed\n",
    "\n",
    "#### 2.4 Testing\n",
    "Different test cases are implemented to see completeness and computing time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "delayed-heavy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# For loop visualization\n",
    "from tqdm import tqdm\n",
    "\n",
    "# For graphical representation\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For algorithm, optimization, evaluation\n",
    "from surprise import Reader, Dataset\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import SVD, accuracy, NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "foster-evening",
   "metadata": {},
   "outputs": [],
   "source": [
    "business = pd.read_csv('clean_business.csv')\n",
    "review = pd.read_csv('clean_review.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "classified-stake",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of restaurants in business dataset:  44202\n",
      "Number of restaurants in review dataset:  209394\n",
      "\n",
      "All business_id from business dataset can be found in review dataset\n"
     ]
    }
   ],
   "source": [
    "print('Number of restaurants in business dataset: ', len(business.business_id.unique()))\n",
    "print('Number of restaurants in review dataset: ', len(review.business_id.unique()))\n",
    "\n",
    "set_bus = set(business.business_id.unique())\n",
    "set_rev = set(review.business_id.unique())\n",
    "\n",
    "if len(set_bus) == len(set_bus.intersection(set_rev)):\n",
    "    print('\\nAll business_id from business dataset can be found in review dataset')\n",
    "else:\n",
    "    print('\\nNot all business_id from business dataset can be found in review dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "technical-cooler",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original datset length:  8021124\n",
      "Reduced dataset length:  7735089\n"
     ]
    }
   ],
   "source": [
    "# Reduced review by removing the duplicated user, restaurant rating combinations\n",
    "\n",
    "review_r = review[~review.duplicated(['user_id','business_id'], keep='first')]\n",
    "\n",
    "# Keep only required columns\n",
    "review_r = review_r[['user_id', 'business_id', 'stars']]\n",
    "review_r = review_r.dropna(axis='index')\n",
    "review_r.reset_index(inplace=True, drop=True)\n",
    "\n",
    "print('Original datset length: ', len(review)) \n",
    "print('Reduced dataset length: ', len(review_r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "forbidden-meeting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OwjRMXRC0KyPrIlcjaXeFQ</td>\n",
       "      <td>-MhfebM0QIsKt87iDN-FNw</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nIJD_7ZXHq-FX8byPMOkMQ</td>\n",
       "      <td>lbrU8StCq3yDfr-QMnGrmQ</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>V34qejxNsCbcgD8C0HVk-Q</td>\n",
       "      <td>HQl28KMwrEKHqhFrrDqVNQ</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ofKDkJKXSKZXu5xJNGiiBQ</td>\n",
       "      <td>5JxlZaqCnk1MnbgRirs40Q</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UgMW8bLE0QMJDCkQ1Ax5Mg</td>\n",
       "      <td>IS4cv902ykd8wj1TR0N3-A</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  user_id             business_id  stars\n",
       "0  OwjRMXRC0KyPrIlcjaXeFQ  -MhfebM0QIsKt87iDN-FNw    2.0\n",
       "1  nIJD_7ZXHq-FX8byPMOkMQ  lbrU8StCq3yDfr-QMnGrmQ    1.0\n",
       "2  V34qejxNsCbcgD8C0HVk-Q  HQl28KMwrEKHqhFrrDqVNQ    5.0\n",
       "3  ofKDkJKXSKZXu5xJNGiiBQ  5JxlZaqCnk1MnbgRirs40Q    1.0\n",
       "4  UgMW8bLE0QMJDCkQ1Ax5Mg  IS4cv902ykd8wj1TR0N3-A    4.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_r.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empirical-madness",
   "metadata": {},
   "source": [
    "### 1 **Ranking**\n",
    "#### 1.1 **SVD (Singular Value Decomposition)**\n",
    "#### 1.1.1 **SVD without bias**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "catholic-conviction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.6311\n",
      "CPU times: user 7min 52s, sys: 7.57 s, total: 7min 59s\n",
      "Wall time: 7min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Reader object with rantings scale\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "# Load trainset, NOTE: the columns must correspond to user id, item id and ratings in the exact order\n",
    "data = Dataset.load_from_df(review_r, reader)\n",
    "\n",
    "# Build training, testing data\n",
    "trainset, testset = train_test_split(data, test_size=0.20)\n",
    "\n",
    "# Algorithm\n",
    "\n",
    "algo = SVD(n_factors=20, n_epochs = 30, biased=False)\n",
    "algo.fit(trainset)\n",
    "predictions = algo.test(testset)\n",
    "accuracy.rmse(predictions)\n",
    "\n",
    "# Gather useful info from model\n",
    "mean = algo.trainset.global_mean \n",
    "user_latent, item_latent = algo.pu, algo.qi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empty-florence",
   "metadata": {},
   "source": [
    "#### 1.1.2 **SVD with bias**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "gorgeous-approach",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.3132\n",
      "CPU times: user 7min 58s, sys: 5.88 s, total: 8min 4s\n",
      "Wall time: 8min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Reader object with rantings scale\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "# Load trainset, NOTE: the columns must correspond to user id, item id and ratings in the exact order\n",
    "data = Dataset.load_from_df(review_r, reader)\n",
    "\n",
    "# Build training, testing data\n",
    "trainset, testset = train_test_split(data, test_size=0.20)\n",
    "\n",
    "# Algorithm\n",
    "\n",
    "algo_bias = SVD(n_factors=20, n_epochs = 30, biased=True)\n",
    "algo_bias.fit(trainset)\n",
    "predictions_bias = algo_bias.test(testset)\n",
    "accuracy.rmse(predictions_bias)\n",
    "\n",
    "# Gather useful info from model\n",
    "mean_bias = algo_bias.trainset.global_mean \n",
    "user_latent_bias, item_latent_bias = algo_bias.pu, algo_bias.qi\n",
    "user_bias, item_bias = algo_bias.bu, algo_bias.bi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "split-covering",
   "metadata": {},
   "source": [
    "#### 1.2 NMF (Non Negative Matrix Factorization)\n",
    "#### 1.2.1 NMF without bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "studied-perfume",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.4638\n",
      "CPU times: user 9min 44s, sys: 7.06 s, total: 9min 51s\n",
      "Wall time: 9min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "algo_nmf = NMF(n_factors=20, n_epochs = 30, biased=False)\n",
    "algo_nmf.fit(trainset)\n",
    "predictions_nmf = algo_nmf.test(testset)\n",
    "accuracy.rmse(predictions_nmf)\n",
    "\n",
    "# Gather useful info from model\n",
    "mean_nmf = algo_nmf.trainset.global_mean \n",
    "user_latent_nmf, item_latent_nmf = algo_nmf.pu, algo_nmf.qi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adequate-zoning",
   "metadata": {},
   "source": [
    "#### 1.2.2 MNF with bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "funded-candidate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.9850\n",
      "CPU times: user 9min 22s, sys: 5 s, total: 9min 27s\n",
      "Wall time: 9min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "algo_nmf_bias = NMF(n_factors=20, n_epochs = 30, biased=True)\n",
    "algo_nmf_bias.fit(trainset)\n",
    "predictions_nmf_bias = algo_nmf_bias.test(testset)\n",
    "accuracy.rmse(predictions_nmf_bias)\n",
    "\n",
    "# Gather useful info from model\n",
    "mean_nmf_bias = algo_nmf_bias.trainset.global_mean \n",
    "user_latent_nmf_bias, item_latent_nmf_bias = algo_nmf_bias.pu, algo_nmf_bias.qi\n",
    "user_nmf_bias, item_nmf_bias = algo_nmf_bias.bu, algo_nmf_bias.bi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desirable-trading",
   "metadata": {},
   "source": [
    "### 2 **Implementation**\n",
    "#### 2.1 **Optimization**"
   ]
  },
  {
   "cell_type": "raw",
   "id": "timely-action",
   "metadata": {},
   "source": [
    "%%time\n",
    "\n",
    "from surprise.model_selection import cross_validate, GridSearchCV, KFold\n",
    "\n",
    "parameters = {'n_factors': [10, 20, 30],\\\n",
    "              'n_epochs': [30, 40, 50],\\\n",
    "              'lr_all': [0.005],\\\n",
    "              'reg_all': [0.05],\\\n",
    "              'biased': [True]}\n",
    "grid_search = GridSearchCV(SVD, parameters, measures=['rmse'], cv=KFold(3, random_state=42))\n",
    "grid_search.fit(data)\n",
    "\n",
    "print('Best score: ', grid_search.best_score)\n",
    "print('Best parameters: ', grid_search.best_paramas)\n",
    "\n",
    "gird_search_optimized = grid_search.best_estimator['rmse']\n",
    "gird_search_optimized.fit(trainset)\n",
    "prediction_optimized = gird_search_optimized.test(testset)\n",
    "accuracy.rmse(prediction_optimized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spread-syntax",
   "metadata": {},
   "source": [
    "#### **Optimized parameters = {'n_factors': 10, 'n_epochs': 50, 'lr_all': 0.005, 'biased': True}**\n",
    "(ran this optimization task on seperate notebook and took 5 hours to run on 8 core CPU, 32 GB VM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "split-tenant",
   "metadata": {},
   "source": [
    "#### 2.2 **Evaluation**\n",
    "#### **NDCG** <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "nasty-patent",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcg_r(r, k):\n",
    "    r = np.asfarray(r)[:min(len(r), k)]                                    # Convert to float type numpy array\n",
    "    if r.size:\n",
    "        return np.sum(r/np.log2(np.arange(2, r.size + 2)))\n",
    "    return None\n",
    "\n",
    "def ndcg_r(r, k):\n",
    "    idcg = dcg_r(sorted(r, reverse=True), k)\n",
    "    dcg = dcg_r(r, k)\n",
    "    if idcg == None or dcg == None:\n",
    "        return None\n",
    "    return dcg/idcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "historical-reset",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.3392\n",
      "CPU times: user 9min 18s, sys: 777 ms, total: 9min 19s\n",
      "Wall time: 9min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Retrain with optimized parameters\n",
    "algo_optimized = SVD(n_factors=10, n_epochs=50, biased=True)\n",
    "algo_optimized.fit(trainset)\n",
    "predictions = algo_optimized.test(testset)\n",
    "accuracy.rmse(predictions)\n",
    "\n",
    "# Gather useful info from model\n",
    "mean_bias = algo_optimized.trainset.global_mean \n",
    "user_latent_bias, item_latent_bias = algo_optimized.pu, algo_optimized.qi\n",
    "user_bias, item_bias = algo_optimized.bu, algo_optimized.bi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "confident-shell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.3392\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.339154610894873"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_one = algo_optimized.test(testset)\n",
    "accuracy.rmse(pred_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "hybrid-england",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1547018/1547018 [01:55<00:00, 13431.41it/s]\n"
     ]
    }
   ],
   "source": [
    "rating_predict_1 = pd.DataFrame(index=np.arange(len(pred_one)),columns=['user_id','business_id','stars','rating_predict'])\n",
    "\n",
    "i=0\n",
    "for entry in tqdm(pred_one):\n",
    "    rating_predict_1.iloc[i,:] = entry.uid, entry.iid, entry.r_ui, entry.est\n",
    "    i += 1    \n",
    "assert i == len(pred_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "actual-perry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranking by predicted ratings:\n",
      "                        rating_predict stars\n",
      "business_id                                \n",
      "t6WY1IrohUecqNjd9bG42Q              5   4.0\n",
      "N8Rwk4XrKaHYXXninuxg9Q              5   5.0\n",
      "zEaGcSVPDQipnRdEZp-F6g              5   2.0\n",
      "Ks0M3J4vZAKsHPuCINz5fQ              5   4.0\n",
      "AZlnpvILz5cEWJifjr2CSQ              5   5.0\n",
      "mz9ltimeAIy2c2qf5ctljw              5   5.0\n",
      "Gv7v-b3Fr_Gvrt6jvmpkJA       4.831041   5.0\n",
      "Od2VpwoOBxycNyQNOMJ6eQ       4.624336   1.0\n",
      "PSRZaGGxXmOmabL2si8pKw       4.519192   3.0\n",
      "YCEZLECK9IToE8Mysorbhw       4.446617   5.0\n",
      "edV_IqWqz5KVSGLrsru5EQ       4.420963   5.0\n",
      "ebJC4iq6oUuiE_XBoEAAOg       4.386198   5.0\n",
      "OicpDroqnfmbtw5jSgf4lQ       4.335283   5.0\n",
      "CWNMLT-ppaUjLMmrnYDPVg       4.234165   5.0\n",
      "cHuA0Yb5oYwx1lrNVABqdQ        4.09728   5.0\n",
      "R-McIj4Psxl1VlEacsXeRg       4.096885   4.0\n",
      "WOO81gScY3_VpaIfXFAKpw       4.016539   4.0\n",
      "gJd1jOcl5FdqY020Q19n6Q       3.791256   5.0\n",
      "DXlDzOcpdUE_F21tok0fgw       3.758748   4.0\n",
      "x-80R4DE6AsYoDtA2H-sKw       3.742237   3.0\n",
      "igHYkXZMLAc9UdV5VnR_AA       3.464978   5.0\n",
      "vW65SNLam99SyOuVagNuvg       3.447683   3.0\n",
      "2BbFeotL85cIaBjSq1SWiA       2.973502   1.0\n",
      "MQiNywdecInMlkW06WYaCg        1.78939   4.0\n",
      "\n",
      "Normalized discounted cumulative gain achieved at top-10 based on testset:\n",
      " 0.7889497770458725\n",
      "\n",
      "Normalized discounted cumulative gain achieved at top-5 based on testset:\n",
      " 0.8012062273946506\n",
      "CPU times: user 10.1 s, sys: 24.7 ms, total: 10.1 s\n",
      "Wall time: 10.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Particular user_id as an example\n",
    "user_id = '---1lKK3aKOuomHnwAkAow'                                              # 12 review ratings available in 'testset'\n",
    "\n",
    "# Rank the 'rating_predict' dataframe by the predicted ratings in descending order\n",
    "rating_predict_1 = rating_predict_1.sort_values('rating_predict', ascending=False)\n",
    "\n",
    "# Filter to the user_id of interest only\n",
    "rec = rating_predict_1[rating_predict_1.user_id == user_id].set_index('business_id')[['rating_predict','stars']]\n",
    "print('Ranking by predicted ratings:\\n', rec)\n",
    "\n",
    "# NDCG @top 10 and @top 5\n",
    "NDCG_10 = ndcg_r(r=rec.stars.values, k=10)\n",
    "NDCG_5 = ndcg_r(r=rec.stars.values, k=5)\n",
    "\n",
    "print('\\nNormalized discounted cumulative gain achieved at top-10 based on testset:\\n', NDCG_10)\n",
    "print('\\nNormalized discounted cumulative gain achieved at top-5 based on testset:\\n', NDCG_5)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "necessary-cigarette",
   "metadata": {},
   "source": [
    "%%time\n",
    "# evaluate NDCG@top10 on the entire testset\n",
    "\n",
    "# only look at NDCG scores for users with at least 10 ratings available in the testset in order to evaluate NDCG@top10\n",
    "rev_count_by_user = rating_predict_1.groupby('user_id').business_id.count()\n",
    "user_id_of_interest = rev_count_by_user[rev_count_by_user >= 10].index\n",
    "\n",
    "# rank the 'rating_predict' dataframe by the predicted ratings in descending order\n",
    "rating_predict_1 = rating_predict_1.sort_values('rating_predict', ascending=False)\n",
    "\n",
    "ndcg_scores_1_10 = []\n",
    "# compute NDCG score for each user in the testset\n",
    "for user_id in tqdm(user_id_of_interest):\n",
    "    \n",
    "    # filter to the user_id of interest only\n",
    "    rec = rating_predict_1[rating_predict_1.user_id == user_id].set_index('business_id')[['rating_predict','stars']]\n",
    "    assert len(rec) >= 10\n",
    "    NDCG = ndcg_r(r=rec.stars.values, k=10) # compute NDCG score@top10\n",
    "    ndcg_scores_1_10.append(NDCG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "adopted-repeat",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store useful information from trained model\n",
    "\n",
    "useful_info = {'mean_rating': algo_optimized.trainset.global_mean,\n",
    "               'user_latent': algo_optimized.pu,\n",
    "               'item_latent': algo_optimized.qi,\n",
    "               'user_bias': algo_optimized.bu,\n",
    "               'item_bias': algo_optimized.bi,\n",
    "               'userid_to_index': algo_optimized.trainset._raw2inner_id_users,\n",
    "               'itemid_to_index': algo_optimized.trainset._raw2inner_id_items\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "sensitive-flooring",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle useful info \n",
    "with open('svd_algo_trained_info', 'wb') as f:\n",
    "    pickle.dump(useful_info, f)\n",
    "    \n",
    "# Pickle trained model\n",
    "with open('svd_bias_algo_trained', 'wb') as f:\n",
    "    pickle.dump(algo_optimized, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "comic-dollar",
   "metadata": {},
   "outputs": [],
   "source": [
    "business = pd.read_csv('clean_business.csv')\n",
    "review = pd.read_csv('clean_review.csv')\n",
    "\n",
    "mean_global = ((business.stars * business.review_count).sum() / (business.review_count.sum()))\n",
    "k = 30                                                                  # 50% quantile of the review counts \n",
    "\n",
    "business['stars_adj'] = ((business.review_count * business.stars) + (k * mean_global)) / (business.review_count + k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "expensive-persian",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recommender_Engine:\n",
    "    \n",
    "    def __init__(self, n=10, stars_original=False):\n",
    "        \"\"\"\n",
    "        Instantiate the object. Default setting for ranking would be stars_adj with top 10 recommendations.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.n = n                                                     # Number of recommendations\n",
    "        self.stars_original = stars_original                           # Boolean for ranking method                            \n",
    "        self.disply_columns = ['name', 'address', 'city','state',\\\n",
    "                               'attributes.RestaurantsPriceRange2',\\\n",
    "                               'review_count','stars','stars_adj',\\\n",
    "                               'cuisine','style']                    # List of columns to be displayed in the results\n",
    "        \n",
    "        if self.stars_original:\n",
    "            score = 'stars'\n",
    "        else:\n",
    "            score = 'stars_adj'\n",
    "            \n",
    "        self.recommendation = business[business.is_open == 1].sort_values(score, ascending=False)\n",
    "                                                                      # Filter only open restaurants\n",
    "    \n",
    "    def display(self):\n",
    "        \n",
    "        if len(self.recommendation) == 0:\n",
    "            print(\"Sorry, there are no matching recommendations.\")\n",
    "        elif self.n < len(self.recommendation):\n",
    "            print(\"Below is the list of the top {} recommended restaurants for you: \".format(self.n))\n",
    "            print(self.recommendation.iloc[:self.n][self.disply_columns])\n",
    "        else:\n",
    "            print(\"Below is the list of the top {} recommended restaurants for you: \".format(len(self.recommendation)))\n",
    "            print(self.recommendation.iloc[self.disply_columns]) \n",
    "    \n",
    "            \n",
    "    def collaborative_filtering(self, user_id=None):\n",
    "        self.user_id = user_id\n",
    "        if self.user_id is None:\n",
    "            print('User ID is not provided')\n",
    "        if len(user_id) != 22:                                        # Sanity check on length of user id\n",
    "            print('Invalid user ID')\n",
    "            return None\n",
    "        \n",
    "        self.recommendation = business[business.is_open == 1]\n",
    "        if 'stars_pred' in self.recommendation.columns:\n",
    "            self.recommendation.drop('stars_pred', axis=1, inplace=True)\n",
    "            \n",
    "        self.display_columns = ['name', 'address', 'city','state',\\\n",
    "                                'attributes.RestaurantsPriceRange2',\\\n",
    "                                'review_count','stars','stars_adj',\\\n",
    "                                'cuisine','style']\n",
    "            \n",
    "        with open('svd_algo_trained_info', rb) as f:\n",
    "            useful_info = pickle.load(f)\n",
    "            \n",
    "        mean_rating = userful_info['mean_rating']\n",
    "        user_latent = userful_info['user_latent']\n",
    "        item_latent = userful_info['ietm_latent']\n",
    "        user_bias = userful_info['user_bias']\n",
    "        item_bias = userful_info['item_bias']\n",
    "        userid_idx = userful_info['userid_to_index']\n",
    "        itemid_idx = userful_info['itemid_to_index']\n",
    "        \n",
    "        # Recommendations\n",
    "        if self.user_id in userid_idx:\n",
    "            u_idx = userid_idx[self.user_id]\n",
    "            pred = mean_rating + user_bias[u_idx] + item_bias + np.dot(user_latent[u_idx,:], ietm_latent.T)\n",
    "        else:\n",
    "            print('Sorry, no personlaized recommendations yet!')\n",
    "            print('\\nHere are generic recommendations: ')\n",
    "            \n",
    "            pred = mean_rating + ietm_bias\n",
    "            \n",
    "        prediction = pd.DataFrame(data=pred, index=itemid_idx.values(), columns=['stars_pred'])\n",
    "        prediction.index.name == 'matrix_item'\n",
    "        assert len(prediction) == len(pred)\n",
    "        prediction['business_id'] = list(itemid_idx.keys())\n",
    "        \n",
    "        # Filter to unrated business by user\n",
    "        if self.user_id in userid_idx:\n",
    "            rated_bus = review[review.user_id == self.user_id].business_id.unique()\n",
    "            prediction = prediction[~prediction.business_id.isn(rated_bus)]\n",
    "            \n",
    "        self.recommendation = self.recommendation.merge(prediction, on='business_id', how='inner')\n",
    "        self.recommendation = self.recommendation.sort_values('stars_pred', ascending=False).reset_index(drop=True)\n",
    "        self.display_columns.insert(0, 'stars_pred')\n",
    "        self.display()\n",
    "        \n",
    "        return self.recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "southeast-satisfaction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test case 1: *****------------*****\n",
      "\n",
      "Below is the list of the top 10 recommended restaurants for you: \n",
      "                          name                           address        city  \\\n",
      "29761          Little Miss BBQ              4301 E University Dr     Phoenix   \n",
      "2648              Brew Tea Bar      7380 S Rainbow Blvd, Ste 101   Las Vegas   \n",
      "33734          Cocina Madrigal                    4044 S 16th St     Phoenix   \n",
      "35172  Green Corner Restaurant        1038 W Southern Ave, Ste 1        Mesa   \n",
      "3590            Worth Takeaway                     218 W Main St        Mesa   \n",
      "9839            Zenaida's Cafe      3430 E Tropicana Ave, Ste 32   Las Vegas   \n",
      "34397          Kodo Sushi Sake  15040 N Northsight Blvd, Ste 104  Scottsdale   \n",
      "21628  Bajamar Seafood & Tacos             1615 S Las Vegas Blvd   Las Vegas   \n",
      "11825                   Karved              3957 S Maryland Pkwy   Las Vegas   \n",
      "34603    Not Your Typical Deli    1166 South Gilbert Rd, Ste 101     Gilbert   \n",
      "\n",
      "      state attributes.RestaurantsPriceRange2  review_count  stars  stars_adj  \\\n",
      "29761    AZ                                 2          2329    5.0   4.984247   \n",
      "2648     NV                                 1          1827    5.0   4.979989   \n",
      "33734    AZ                                 2          1107    5.0   4.967317   \n",
      "35172    AZ                                 2           858    5.0   4.958153   \n",
      "3590     AZ                                 2           842    5.0   4.957385   \n",
      "9839     NV                                 2           717    5.0   4.950254   \n",
      "34397    AZ                                 2           695    5.0   4.948744   \n",
      "21628    NV                                 1           658    5.0   4.945988   \n",
      "11825    NV                                 2           651    5.0   4.945433   \n",
      "34603    AZ                                 2           645    5.0   4.944948   \n",
      "\n",
      "                                                 cuisine  \\\n",
      "29761                                           barbeque   \n",
      "2648                                 bubble tea,desserts   \n",
      "33734                                            mexican   \n",
      "35172               mediterranean,sandwiches,greek,salad   \n",
      "3590    american (traditional),american (new),sandwiches   \n",
      "9839                                                 NaN   \n",
      "34397                                sushi bars,japanese   \n",
      "21628                              tacos,seafood,mexican   \n",
      "11825  sandwiches,salad,american (new),american (trad...   \n",
      "34603                                         sandwiches   \n",
      "\n",
      "                                                style  \n",
      "29761                                     restaurants  \n",
      "2648                                restaurants,cafes  \n",
      "33734                                     restaurants  \n",
      "35172                                     restaurants  \n",
      "3590                   breakfast & brunch,restaurants  \n",
      "9839             cafes,breakfast & brunch,restaurants  \n",
      "34397                                     restaurants  \n",
      "21628  fast food,dive bars,bars,nightlife,restaurants  \n",
      "11825                           restaurants,fast food  \n",
      "34603                      restaurants,delis,caterers  \n",
      "Test case 1: *****------------*****\n",
      "\n",
      "User ID is not provided\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-114b6dab9510>\u001b[0m in \u001b[0;36mcollaborative_filtering\u001b[0;34m(self, user_id)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_id\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'User ID is not provided'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m22\u001b[0m\u001b[0;34m:\u001b[0m                                        \u001b[0;31m# Sanity check on length of user id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Invalid user ID'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Instantiate the object\n",
    "results = Recommender_Engine();\n",
    "\n",
    "# Test case 1: Display results\n",
    "print('Test case 1: *****------------*****\\n');\n",
    "results.display();\n",
    "\n",
    "# Test case 1: No user_id input\n",
    "print('Test case 1: *****------------*****\\n');\n",
    "results.collaborative_filtering();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "junior-breakdown",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-4.mnightly-2021-02-02-debian-10-test",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-4:mnightly-2021-02-02-debian-10-test"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
